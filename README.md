# ğŸ—³ï¸ Electio-Analytics - Projet de PrÃ©diction Ã‰lectorale
## POC - DÃ©partement de l'HÃ©rault (34)

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![PySpark](https://img.shields.io/badge/PySpark-3.x-orange.svg)](https://spark.apache.org/docs/latest/api/python/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture du projet](#architecture-du-projet)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure des donnÃ©es](#structure-des-donnÃ©es)
- [Pipeline ETL](#pipeline-etl)
- [ModÃ¨le prÃ©dictif](#modÃ¨le-prÃ©dictif)
- [Livrables](#livrables)
- [Ã‰quipe](#Ã©quipe)

---

## ğŸ¯ Vue d'ensemble

Ce projet constitue une **Preuve de Concept (POC)** pour **Electio-Analytics**, start-up spÃ©cialisÃ©e dans le conseil stratÃ©gique Ã©lectoral. L'objectif est de construire un modÃ¨le prÃ©dictif des tendances Ã©lectorales Ã  moyen terme (1 Ã  3 ans) basÃ© sur des indicateurs socio-Ã©conomiques.

### Objectifs

- âœ… Valider la faisabilitÃ© d'un modÃ¨le prÃ©dictif Ã©lectoral
- âœ… Identifier les indicateurs les plus corrÃ©lÃ©s aux rÃ©sultats Ã©lectoraux
- âœ… Construire un pipeline ETL automatisÃ© et reproductible
- âœ… Fournir des visualisations exploitables pour la prise de dÃ©cision

### PÃ©rimÃ¨tre

- **GÃ©ographie :** DÃ©partement de l'HÃ©rault (34) - 342 communes
- **Ã‰lections :** Municipales 2020 (2e tour)
- **Indicateurs :** DÃ©mographie, emploi, Ã©ducation, pauvretÃ©, logement

---

## ğŸ—ï¸ Architecture du Projet

```
tada/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # DonnÃ©es brutes (CSV sources)
â”‚   â”œâ”€â”€ processed/              # DonnÃ©es nettoyÃ©es par dataset
â”‚   â””â”€â”€ final/                  # Base de donnÃ©es intÃ©grÃ©e (SQLite)
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py              # Fonctions d'extraction Spark
â”‚   â”œâ”€â”€ transform.py            # Fonctions de transformation
â”‚   â”œâ”€â”€ load.py                 # Fonctions de chargement
â”‚   â”œâ”€â”€ main.py                 # Pipeline ETL principal
â”‚   â””â”€â”€ integrate.py            # IntÃ©gration et fusion des sources
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_analyse_exploratoire.ipynb   # EDA et corrÃ©lations
â”‚   â””â”€â”€ 02_modele_predictif.ipynb       # ML et prÃ©dictions
â”‚
â”œâ”€â”€ models/                     # ModÃ¨les ML sauvegardÃ©s
â”œâ”€â”€ visualisations/             # Graphiques et cartes
â”œâ”€â”€ sql/                        # SchÃ©mas de base de donnÃ©es
â”‚
â”œâ”€â”€ documentation/
â”‚   â””â”€â”€ 01_dossier_de_synthese.md   # Rapport complet du projet
â”‚
â”œâ”€â”€ config.py                   # Configuration du projet
â””â”€â”€ README.md                   # Ce fichier

```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.11+
- Java 8+ (pour PySpark)
- Git

### Ã‰tapes d'installation

1. **Cloner le repository**
```bash
git clone <url-du-repo>
cd tada
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

### DÃ©pendances principales

```txt
pandas>=2.0.0
numpy>=1.24.0
pyspark>=3.4.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
jupyter>=1.0.0
sqlite3
openpyxl
```

---

## ğŸ’» Utilisation

### 1. ExÃ©cuter le Pipeline ETL

```bash
# Nettoyer et transformer toutes les donnÃ©es
python etl/main.py

# IntÃ©grer les donnÃ©es dans une base SQLite
python etl/integrate.py
```

**RÃ©sultat :** 
- Fichiers CSV nettoyÃ©s dans `data/processed/`
- Base SQLite dans `data/final/electio_analytics.db`

### 2. Lancer l'Analyse Exploratoire

```bash
jupyter notebook notebooks/01_analyse_exploratoire.ipynb
```

**Contenu :**
- Chargement et exploration des donnÃ©es
- Statistiques descriptives
- Analyse de corrÃ©lation
- Visualisations (histogrammes, heatmaps, cartes)

### 3. EntraÃ®ner le ModÃ¨le PrÃ©dictif

```bash
jupyter notebook notebooks/02_modele_predictif.ipynb
```

**Contenu :**
- PrÃ©paration des features
- Train/Test split
- EntraÃ®nement de modÃ¨les (Random Forest, Gradient Boosting, etc.)
- Ã‰valuation des performances (RÂ², RMSE, MAE)
- PrÃ©dictions Ã  1, 2 et 3 ans

---

## ğŸ“Š Structure des DonnÃ©es

### Sources de DonnÃ©es (Raw)

| Fichier | Description | Source |
|---------|-------------|--------|
| `DT PRINCIPAL elections-municipales-2020-resultats-du-2eme-tour.csv` | RÃ©sultats Ã©lectoraux 2020 | MinistÃ¨re IntÃ©rieur |
| `evolution-de-la-population-par-tranches-dage-dans-lherault.csv` | DÃ©mographie par Ã¢ge | INSEE |
| `logements-par-categorie-herault.csv` | Statistiques logement | INSEE |
| `Niveau de vie median et taux de pauvrete par type de menage.csv` | Indicateurs de pauvretÃ© | INSEE |
| `niveau-de-diplome-de-la-population-herault.csv` | Niveau d'Ã©ducation | INSEE |
| `population-active-herault.csv` | Emploi et chÃ´mage | INSEE |
| `population par categorie socioprofessionelle.csv` | CSP | INSEE |
| `communes-france-2025 (1).csv` | RÃ©fÃ©rentiel communes | Data.gouv.fr |

### Base de DonnÃ©es Finale

**Format :** SQLite  
**Localisation :** `data/final/electio_analytics.db`

**Tables principales :**
- `communes` : RÃ©fÃ©rentiel des communes de l'HÃ©rault
- `elections_2020` : RÃ©sultats Ã©lectoraux
- `demographie` : DonnÃ©es de population par Ã¢ge
- `pauvrete` : Niveau de vie et taux de pauvretÃ©
- `education` : Niveau de diplÃ´me
- `emploi` : Population active et chÃ´mage
- `logement` : Statistiques de logement
- `sociopro` : CatÃ©gories socioprofessionnelles

---

## ğŸ”„ Pipeline ETL

### Extraction (`extract.py`)

- Chargement des fichiers CSV via PySpark
- DÃ©tection automatique du schÃ©ma
- Gestion des erreurs de format

### Transformation (`transform.py`)

**Fonctions principales :**
- `clean_column_names()` : Normalisation des noms de colonnes
- `remove_duplicates()` : Suppression des doublons
- `handle_missing_values()` : Gestion des valeurs manquantes
- `normalize_commune_names()` : Standardisation des noms de communes
- `cast_columns_types()` : Conversion des types de donnÃ©es
- `filter_department()` : Filtrage pour l'HÃ©rault (34)

### Chargement (`load.py`)

**Formats d'export :**
- CSV : Format universel
- SQLite : Base relationnelle pour analyses
- Parquet : Format optimisÃ© pour big data

### Orchestration (`main.py`)

Pipeline complet automatisÃ© :
1. Chargement de toutes les sources
2. Nettoyage et normalisation
3. Export des donnÃ©es traitÃ©es
4. GÃ©nÃ©ration de rapports de synthÃ¨se

---

## ğŸ¤– ModÃ¨le PrÃ©dictif

### Approche

- **Type :** Apprentissage supervisÃ© (rÃ©gression)
- **Variable cible (Y) :** Score de la liste majoritaire (%)
- **Features (X) :** Indicateurs socio-Ã©conomiques

### ModÃ¨les TestÃ©s

1. **Linear Regression** : Baseline simple
2. **Random Forest** : Ensemble d'arbres de dÃ©cision
3. **Gradient Boosting** : Boosting sÃ©quentiel
4. **XGBoost** : Optimisation avancÃ©e

### MÃ©triques d'Ã‰valuation

- **RÂ² (R-squared)** : Proportion de variance expliquÃ©e
- **RMSE** : Erreur quadratique moyenne
- **MAE** : Erreur absolue moyenne
- **Cross-validation** : Validation croisÃ©e 5-folds

### RÃ©sultats

*Ã€ complÃ©ter aprÃ¨s exÃ©cution du notebook de modÃ©lisation*

---

## ğŸ“¦ Livrables

### 1. Dossier de SynthÃ¨se

**Localisation :** `documentation/01_dossier_de_synthese.md`

**Contenu :**
- Justification du pÃ©rimÃ¨tre gÃ©ographique
- Choix et justification des critÃ¨res
- DÃ©marche mÃ©thodologique
- ModÃ¨le Conceptuel de DonnÃ©es (MCD)
- ModÃ¨les testÃ©s et rÃ©sultats
- Visualisations
- Accuracy et performance
- RÃ©ponses aux questions d'analyse

### 2. Jeu de DonnÃ©es NettoyÃ©

**Localisation :** `data/final/electio_analytics.db`

**Format :** SQLite (compatible SQL)

**SchÃ©ma :** `sql/schema.sql`

### 3. Code Source CommentÃ©

- **ETL :** `etl/`
- **Notebooks :** `notebooks/`
- **Configuration :** `config.py`

Tous les scripts sont documentÃ©s avec docstrings et commentaires.

### 4. Support de PrÃ©sentation

*Ã€ crÃ©er pour la soutenance (PowerPoint ou Ã©quivalent)*

**DurÃ©e :** 20 minutes de prÃ©sentation + 30 minutes d'Ã©changes

---

## ğŸ” Questions d'Analyse

### Q1 : Quelle donnÃ©e est la plus corrÃ©lÃ©e aux rÃ©sultats Ã©lectoraux ?

**RÃ©ponse :** Voir le notebook `01_analyse_exploratoire.ipynb` et le dossier de synthÃ¨se.

La matrice de corrÃ©lation rÃ©vÃ¨le que **[INDICATEUR]** prÃ©sente la corrÃ©lation la plus forte (r = [XX]).

### Q2 : DÃ©finissez le principe d'un apprentissage supervisÃ©

**RÃ©ponse :** L'apprentissage supervisÃ© est une mÃ©thode de machine learning oÃ¹ l'algorithme apprend Ã  partir de donnÃ©es Ã©tiquetÃ©es (avec rÃ©sultats connus) pour prÃ©dire des rÃ©sultats futurs.

**Dans notre projet :**
- **DonnÃ©es d'entraÃ®nement :** RÃ©sultats Ã©lectoraux 2020 + indicateurs socio-Ã©conomiques
- **ModÃ¨le :** Apprend les relations entre indicateurs et rÃ©sultats
- **PrÃ©diction :** RÃ©sultats Ã©lectoraux futurs (2026-2028)

Voir dÃ©tails dans `documentation/01_dossier_de_synthese.md`.

### Q3 : Comment dÃ©finissez-vous la prÃ©cision (accuracy) du modÃ¨le ?

**RÃ©ponse :** Pour un modÃ¨le de rÃ©gression, nous utilisons :

- **RÂ²** : Proportion de variance expliquÃ©e (0 Ã  1)
- **RMSE** : Erreur quadratique moyenne (en points de %)
- **MAE** : Erreur absolue moyenne (en points de %)

**Exemple d'interprÃ©tation :**
- RÂ² = 0.85 â†’ Le modÃ¨le explique 85% de la variabilitÃ©
- MAE = 3.2 â†’ Erreur moyenne de Â±3.2 points de %

Voir rÃ©sultats dÃ©taillÃ©s dans `notebooks/02_modele_predictif.ipynb`.

---

## ğŸ‘¥ Ã‰quipe

**Membres du projet :**
- [Nom 1] - Chef de projet / Data Scientist
- [Nom 2] - Data Engineer
- [Nom 3] - Data Analyst
- [Nom 4] - Visualisation / Reporting

**Client :** Electio-Analytics  
**PÃ©riode :** Janvier 2026  
**DurÃ©e :** 25 heures de prÃ©paration

---

## ğŸ“š Ressources ComplÃ©mentaires

### Documentation

- [Dossier de synthÃ¨se complet](documentation/01_dossier_de_synthese.md)
- [SchÃ©ma de base de donnÃ©es](sql/schema.sql)
- [Configuration du projet](config.py)

### Liens Externes

- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [INSEE - DonnÃ©es communales](https://www.insee.fr)
- [Data.gouv.fr - Open Data](https://www.data.gouv.fr)

### Gestion de Projet

Lien du Trello : <https://trello.com/invite/b/6964c47ad0851811af02e0f1/ATTI4561ee92c155d0309722f321b591ce4757F69540/mspr-big-data-analyse-de-donnees>

---

## ğŸ“„ Licence

Ce projet est dÃ©veloppÃ© dans le cadre d'une MSPR acadÃ©mique.

---

## ğŸ“ Contact

Pour toute question sur le projet :
- **Email :** [email@example.com]
- **GitHub :** [lien-github]

---

**DerniÃ¨re mise Ã  jour :** Janvier 2026
